{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dd5d4a9-9aeb-41ca-a394-584168069e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saurabhkumar/miniforge3/envs/job_classifier/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import sentence_transformers\n",
    "import ctransformers\n",
    "import pandas\n",
    "import matplotlib\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8437f2e5-9b06-4009-8642-3412ce4fe9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è System Check Starting...\n",
      "\n",
      "üß™ Python version: 3.10.16\n",
      "üíæ Total RAM: 16.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SentenceTransformer MiniLM model loaded and embedding successful.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.97it/s]\n",
      "Fetching 0 files: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mistral-7B-Instruct model loaded via CTransformers successfully.\n",
      "‚ùå ChromaDB failed: \u001b[91mYou are using a deprecated configuration of Chroma.\n",
      "\n",
      "\u001b[94mIf you do not have data you wish to migrate, you only need to change how you construct\n",
      "your Chroma client. Please see the \"New Clients\" section of https://docs.trychroma.com/deployment/migration.\n",
      "________________________________________________________________________________________________\n",
      "\n",
      "If you do have data you wish to migrate, we have a migration tool you can use in order to\n",
      "migrate your data to the new Chroma architecture.\n",
      "Please `pip install chroma-migrate` and run `chroma-migrate` to migrate your data and then\n",
      "change how you construct your Chroma client.\n",
      "\n",
      "See https://docs.trychroma.com/deployment/migration for more information or join our discord at https://discord.gg/MMeYNTmh3x for help!\u001b[0m\n",
      "\n",
      "‚úÖ‚úÖ‚úÖ System Ready!\n"
     ]
    }
   ],
   "source": [
    "# ====== System Check Script ======\n",
    "\n",
    "import platform\n",
    "import os\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "print(\"‚öôÔ∏è System Check Starting...\\n\")\n",
    "\n",
    "# --- Python Version ---\n",
    "print(f\"üß™ Python version: {platform.python_version()}\")\n",
    "\n",
    "# --- RAM Check ---\n",
    "import psutil\n",
    "mem = psutil.virtual_memory()\n",
    "print(f\"üíæ Total RAM: {round(mem.total / (1024**3), 2)} GB\")\n",
    "\n",
    "# --- Embedding Model Test ---\n",
    "try:\n",
    "    embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    test_emb = embedder.encode([\"This is a test sentence.\"])\n",
    "    print(\"‚úÖ SentenceTransformer MiniLM model loaded and embedding successful.\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Embedding model failed:\", e)\n",
    "\n",
    "# --- LLM Model Load Test ---\n",
    "try:\n",
    "    llm = AutoModelForCausalLM.from_pretrained(\n",
    "        \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\",\n",
    "        model_file=\"/Users/saurabhkumar/Desktop/UK_JOB_OECD/LLM/mistral-7b-instruct-v0.2.Q4_K_M.gguf\",\n",
    "        model_type=\"mistral\",\n",
    "        gpu_layers=0  # CPU only\n",
    "    )\n",
    "    print(\"‚úÖ Mistral-7B-Instruct model loaded via CTransformers successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå LLM model failed to load:\", e)\n",
    "\n",
    "# --- ChromaDB Test ---\n",
    "try:\n",
    "    db_dir = \"./chromadb_test\"\n",
    "    os.makedirs(db_dir, exist_ok=True)\n",
    "    client = chromadb.Client(chromadb.config.Settings(chroma_db_impl=\"duckdb+parquet\", persist_directory=db_dir))\n",
    "    collection = client.create_collection(name=\"test_collection\")\n",
    "    collection.add(documents=[\"Hello World!\"], ids=[\"test1\"], metadatas=[{\"test\": \"ok\"}])\n",
    "    results = collection.query(query_texts=[\"Hello\"], n_results=1)\n",
    "    print(\"‚úÖ ChromaDB simple retrieval successful.\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå ChromaDB failed:\", e)\n",
    "\n",
    "print(\"\\n‚úÖ‚úÖ‚úÖ System Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3d0cfe0-47f6-4eb1-a776-c76a6596aa4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 2557.50it/s]\n",
      "Fetching 0 files: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Job Advert 1:\n",
      "We are looking for someone to create dashboards and analyze customer trends using SQL and Power BI.\n",
      "\n",
      "üîç Prediction:\n",
      "\n",
      "## Your Solution\n",
      "\n",
      "SOC_CODE = \"2425\"  # Replace this line with your solution\n",
      "DATA_LABEL = \"Data Analytics\"  # Replace this line with your solution\n",
      "\n",
      "print(f'SOC_CODE: {SOC_CODE}, DATA_LABEL: {DATA_LABEL}')\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìù Job Advert 2:\n",
      "The candidate will perform daily database updates and maintain records accurately.\n",
      "\n",
      "üîç Prediction:\n",
      "\n",
      "Answer:\n",
      "SOC_CODE: 4112\n",
      "DATA_LABEL: Data Entry\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìù Job Advert 3:\n",
      "Looking for a software developer to design and implement new APIs in Python.\n",
      "\n",
      "üîç Prediction:\n",
      "\n",
      "# Answer:\n",
      "SOC_CODE: 2136\n",
      "DATA_LABEL: None\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìù Job Advert 4:\n",
      "Seeking an expert in machine learning models to work on predictive analytics.\n",
      "\n",
      "üîç Prediction:\n",
      "\n",
      "Based on the provided job description, my analysis is as follows:\n",
      "\n",
      "SOC_CODE: 2425 - Data Analyst\n",
      "DATA_LABEL: Data Analytics\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ====== Tiny End-to-End Test for SOC and Data Label Prediction ======\n",
    "\n",
    "# Step 1 - Imports (you already have these)\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from ctransformers import AutoModelForCausalLM\n",
    "import os\n",
    "\n",
    "# Step 2 - Load Models (embedder + LLM)\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "llm = AutoModelForCausalLM.from_pretrained(\n",
    "    \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\",\n",
    "    model_file=\"/Users/saurabhkumar/Desktop/UK_JOB_OECD/LLM/mistral-7b-instruct-v0.2.Q4_K_M.gguf\",  # Change this path!\n",
    "    model_type=\"mistral\",\n",
    "    gpu_layers=0  # CPU-only\n",
    ")\n",
    "\n",
    "# Step 3 - Dummy Knowledge Base (tiny SOC + labels)\n",
    "soc_data = [\n",
    "    {\"soc_code\": \"2425\", \"title\": \"Data Analyst\", \"description\": \"Collects and analyzes data for decision making.\"},\n",
    "    {\"soc_code\": \"2136\", \"title\": \"Software Engineer\", \"description\": \"Develops and maintains software applications.\"},\n",
    "    {\"soc_code\": \"4112\", \"title\": \"Data Entry Clerk\", \"description\": \"Inputs information into databases and systems.\"},\n",
    "    {\"soc_code\": \"2421\", \"title\": \"Management Consultant\", \"description\": \"Advises businesses on management strategies.\"}\n",
    "]\n",
    "\n",
    "data_labels = [\n",
    "    {\"label\": \"Data Science\", \"description\": \"Tasks involving machine learning, predictive modeling, AI.\"},\n",
    "    {\"label\": \"Data Analytics\", \"description\": \"Tasks involving interpretation, visualization, reporting of data.\"},\n",
    "    {\"label\": \"Database Management\", \"description\": \"Tasks managing databases, SQL servers, warehouses.\"},\n",
    "    {\"label\": \"Data Entry\", \"description\": \"Tasks inputting or updating information into databases.\"}\n",
    "]\n",
    "\n",
    "# Step 4 - Create Fake ChromaDB Collections (in-memory)\n",
    "# Step 4 - Create or Get Collections Safely\n",
    "import chromadb\n",
    "\n",
    "db_dir = \"./chromadb_test\"\n",
    "os.makedirs(db_dir, exist_ok=True)\n",
    "\n",
    "client = chromadb.Client()  # Updated no settings\n",
    "\n",
    "# Corrected: get_or_create instead of create\n",
    "soc_collection = client.get_or_create_collection(name=\"soc_codes\")\n",
    "data_label_collection = client.get_or_create_collection(name=\"data_labels\")\n",
    "\n",
    "# Add SOCs (only if collection empty)\n",
    "if len(soc_collection.get()['ids']) == 0:\n",
    "    for entry in soc_data:\n",
    "        soc_collection.add(documents=[entry['description']], metadatas=[{\"soc_code\": entry['soc_code'], \"title\": entry['title']}], ids=[entry['soc_code']])\n",
    "\n",
    "if len(data_label_collection.get()['ids']) == 0:\n",
    "    for label in data_labels:\n",
    "        data_label_collection.add(documents=[label['description']], metadatas=[{\"label\": label['label']}], ids=[label['label']])\n",
    "\n",
    "# NO persist() call anymore. ‚úÖ\n",
    "\n",
    "# Step 5 - Function to Classify a Job\n",
    "def classify_job(job_description):\n",
    "    # Embed\n",
    "    job_embedding = embedder.encode(job_description)\n",
    "\n",
    "    # Retrieve SOCs\n",
    "    soc_results = soc_collection.query(query_texts=[job_description], n_results=3)\n",
    "    soc_candidates = soc_results['documents'][0]\n",
    "    soc_metadata = soc_results['metadatas'][0]\n",
    "\n",
    "    # Retrieve Data labels\n",
    "    label_results = data_label_collection.query(query_texts=[job_description], n_results=4)\n",
    "    label_candidates = label_results['documents'][0]\n",
    "    label_metadata = label_results['metadatas'][0]\n",
    "\n",
    "    # Build prompt\n",
    "    prompt = f\"\"\"\n",
    "You are an expert job classifier.\n",
    "\n",
    "Here is a Job Description:\n",
    "\\\"\\\"\\\"\n",
    "{job_description}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "First, select the most appropriate SOC code among these options:\n",
    "{[m['soc_code'] + \" - \" + m['title'] for m in soc_metadata]}\n",
    "\n",
    "Second, decide whether this job falls into one of these data categories:\n",
    "{[m['label'] for m in label_metadata]}\n",
    "or None if it does not match.\n",
    "\n",
    "Output format:\n",
    "SOC_CODE: <best matching SOC code>\n",
    "DATA_LABEL: <Data Science / Data Analytics / Database Management / Data Entry / None>\n",
    "    \"\"\"\n",
    "\n",
    "    # Predict\n",
    "    prediction = llm(prompt)\n",
    "\n",
    "    return prediction\n",
    "\n",
    "# Step 6 - Test with Example Jobs\n",
    "\n",
    "job_ads = [\n",
    "    \"We are looking for someone to create dashboards and analyze customer trends using SQL and Power BI.\",\n",
    "    \"The candidate will perform daily database updates and maintain records accurately.\",\n",
    "    \"Looking for a software developer to design and implement new APIs in Python.\",\n",
    "    \"Seeking an expert in machine learning models to work on predictive analytics.\"\n",
    "]\n",
    "\n",
    "# Run the prediction\n",
    "for idx, ad in enumerate(job_ads):\n",
    "    print(f\"\\nüìù Job Advert {idx+1}:\")\n",
    "    print(ad)\n",
    "    print(\"\\nüîç Prediction:\")\n",
    "    print(classify_job(ad))\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65560daa-5ee1-4bfb-a821-470177701149",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/blob/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b6d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install chromadb sentence-transformers pandas matplotlib faiss-cpu\n",
    "pip install ctransformers\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
